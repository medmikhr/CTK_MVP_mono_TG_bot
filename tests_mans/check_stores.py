#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â
"""

import os
from dotenv import load_dotenv
from document_processor_langchain import PERSIST_DIR
from embeddings_manager import get_local_huggingface_embeddings
from langchain_chroma import Chroma

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

def check_vector_stores():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â."""
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â")
    print("=" * 40)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è embeddings
        print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è embeddings...")
        embeddings = get_local_huggingface_embeddings()
        print("‚úÖ Embeddings –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        print(f"\n–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {PERSIST_DIR}")
        if os.path.exists(PERSIST_DIR):
            print("‚úÖ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            files = os.listdir(PERSIST_DIR)
            print(f"   –§–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {len(files)}")
            for file in files:
                print(f"   - {file}")
        else:
            print("‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return False
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ö—Ä–∞–Ω–∏–ª–∏—â
        stores = {
            "dama": Chroma(collection_name="dama", persist_directory=PERSIST_DIR, embedding_function=embeddings),
            "ctk": Chroma(collection_name="ctk", persist_directory=PERSIST_DIR, embedding_function=embeddings),
            "sbf": Chroma(collection_name="sbf", persist_directory=PERSIST_DIR, embedding_function=embeddings)
        }
        
        print("\n–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ö—Ä–∞–Ω–∏–ª–∏—â:")
        total_docs = 0
        
        for name, store in stores.items():
            try:
                count = store._collection.count()
                print(f"   {name.upper()}: {count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                total_docs += count
                
                # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
                if count > 0:
                    docs = store.similarity_search("—Ç–µ—Å—Ç", k=1)
                    print(f"     ‚úÖ –ü–æ–∏—Å–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç")
                else:
                    print(f"     ‚ö†Ô∏è  –•—Ä–∞–Ω–∏–ª–∏—â–µ –ø—É—Å—Ç–æ–µ")
                    
            except Exception as e:
                print(f"   {name.upper()}: ‚ùå –û—à–∏–±–∫–∞ - {e}")
        
        print(f"\n–ò—Ç–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_docs}")
        
        if total_docs == 0:
            print("\n‚ö†Ô∏è  –í—Å–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø—É—Å—Ç—ã–µ!")
            print("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
            print("1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ bulk_upload.py –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            print("2. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ agent_simple.py –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return False
        else:
            print("\n‚úÖ –•—Ä–∞–Ω–∏–ª–∏—â–∞ –≥–æ—Ç–æ–≤—ã –∫ —Ä–∞–±–æ—Ç–µ")
            return True
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ö—Ä–∞–Ω–∏–ª–∏—â: {e}")
        return False

if __name__ == "__main__":
    success = check_vector_stores()
    if not success:
        print("\n‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å —Ö—Ä–∞–Ω–∏–ª–∏—â–∞–º–∏")
    else:
        print("\n‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ") 