#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
"""

import os
import logging
from typing import List, Dict, Any
from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader
import time
import sys

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DocumentLoader:
    """–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞."""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
        self.setup_embeddings()
        self.setup_vector_stores()
        self.setup_text_splitter()
        
    def setup_embeddings(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ embeddings."""
        self.embeddings = HuggingFaceEmbeddings(
            model_name="cointegrated/rubert-tiny2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        logger.info("Embeddings –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        
    def setup_vector_stores(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â."""
        persist_dir = "./vector_stores"
        os.makedirs(persist_dir, exist_ok=True)
        
        # –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ DAMA DMBOK
        self.dama_store = Chroma(
            collection_name="dama_dmbok",
            persist_directory=persist_dir,
            embedding_function=self.embeddings
        )
        
        # –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –¶–¢–ö
        self.ctk_store = Chroma(
            collection_name="ctk_methodology",
            persist_directory=persist_dir,
            embedding_function=self.embeddings
        )
        
        logger.info("–í–µ–∫—Ç–æ—Ä–Ω—ã–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        
    def setup_text_splitter(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è —Ç–µ–∫—Å—Ç–∞."""
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )
        logger.info("–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Ç–µ–∫—Å—Ç–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        
    def load_pdf_documents(self, directory: str, collection_name: str) -> List[Document]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
        
        Args:
            directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å PDF —Ñ–∞–π–ª–∞–º–∏
            collection_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            
        Returns:
            –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        documents = []
        
        if not os.path.exists(directory):
            logger.warning(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {directory} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return documents
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ PDF —Ñ–∞–π–ª—ã –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            loader = DirectoryLoader(
                directory,
                glob="**/*.pdf",
                loader_cls=PyPDFLoader
            )
            
            loaded_docs = loader.load()
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(loaded_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {directory}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            for doc in loaded_docs:
                doc.metadata["collection"] = collection_name
                doc.metadata["file_type"] = "pdf"
                
            documents.extend(loaded_docs)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {directory}: {e}")
        
        return documents
    
    def split_documents(self, documents: List[Document]) -> List[Document]:
        """
        –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —á–∞–Ω–∫–∏.
        
        Args:
            documents: –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        try:
            split_docs = self.text_splitter.split_documents(documents)
            logger.info(f"–†–∞–∑–¥–µ–ª–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ {len(split_docs)} —á–∞–Ω–∫–æ–≤")
            return split_docs
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            return documents
    
    def add_documents_to_store(self, documents: List[Document], store: Chroma, store_name: str):
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.
        
        Args:
            documents: –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            store: –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            store_name: –ù–∞–∑–≤–∞–Ω–∏–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        try:
            if not documents:
                logger.warning(f"–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ {store_name}")
                return
            
            # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            store._collection.delete(where={})
            logger.info(f"–û—á–∏—â–µ–Ω–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ {store_name}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            store.add_documents(documents)
            store.persist()
            
            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ {store_name}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ {store_name}: {e}")
    
    def load_dama_documents(self, dama_directory: str):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ DAMA DMBOK.
        
        Args:
            dama_directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ DAMA
        """
        print(f"\nüìö –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ DAMA DMBOK –∏–∑ {dama_directory}")
        print("=" * 50)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        documents = self.load_pdf_documents(dama_directory, "dama_dmbok")
        
        if not documents:
            print("‚ö†Ô∏è  –î–æ–∫—É–º–µ–Ω—Ç—ã DAMA –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —á–∞–Ω–∫–∏
        split_docs = self.split_documents(documents)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        self.add_documents_to_store(split_docs, self.dama_store, "DAMA DMBOK")
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(split_docs)} —á–∞–Ω–∫–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ DAMA DMBOK")
    
    def load_ctk_documents(self, ctk_directory: str):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –¶–¢–ö.
        
        Args:
            ctk_directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ –¶–¢–ö
        """
        print(f"\nüìö –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –¶–¢–ö –∏–∑ {ctk_directory}")
        print("=" * 50)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        documents = self.load_pdf_documents(ctk_directory, "ctk_methodology")
        
        if not documents:
            print("‚ö†Ô∏è  –î–æ–∫—É–º–µ–Ω—Ç—ã –¶–¢–ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —á–∞–Ω–∫–∏
        split_docs = self.split_documents(documents)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        self.add_documents_to_store(split_docs, self.ctk_store, "–¶–¢–ö")
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(split_docs)} —á–∞–Ω–∫–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¶–¢–ö")
    
    def get_store_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â–∞—Ö."""
        try:
            dama_count = self.dama_store._collection.count()
            ctk_count = self.ctk_store._collection.count()
            
            return {
                "dama_dmbok": {
                    "documents": dama_count,
                    "status": "ready" if dama_count > 0 else "empty"
                },
                "ctk_methodology": {
                    "documents": ctk_count,
                    "status": "ready" if ctk_count > 0 else "empty"
                }
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞—Ö: {e}")
            return {"error": str(e)}

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
    print("üöÄ –ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–≥–µ–Ω—Ç–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã–º–∏")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) < 3:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  python load_documents.py <dama_directory> <ctk_directory>")
        print("")
        print("–ü—Ä–∏–º–µ—Ä:")
        print("  python load_documents.py ../dama_docs ../ctk_docs")
        print("")
        print("–ï—Å–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é:")
        print("  DAMA: ../dama_docs")
        print("  –¶–¢–ö: ../ctk_docs")
        print("")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        dama_dir = "../dama_docs"
        ctk_dir = "../ctk_docs"
    else:
        dama_dir = sys.argv[1]
        ctk_dir = sys.argv[2]
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫
        loader = DocumentLoader()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ö—Ä–∞–Ω–∏–ª–∏—â
        print("\nüìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ö—Ä–∞–Ω–∏–ª–∏—â:")
        store_info = loader.get_store_info()
        for store_name, info in store_info.items():
            if "error" not in info:
                status_icon = "‚úÖ" if info["status"] == "ready" else "‚ö†Ô∏è"
                print(f"   {status_icon} {store_name}: {info['documents']} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            else:
                print(f"   ‚ùå {store_name}: –æ—à–∏–±–∫–∞ - {info['error']}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã DAMA
        if os.path.exists(dama_dir):
            loader.load_dama_documents(dama_dir)
        else:
            print(f"\n‚ö†Ô∏è  –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è DAMA –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {dama_dir}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –¶–¢–ö
        if os.path.exists(ctk_dir):
            loader.load_ctk_documents(ctk_dir)
        else:
            print(f"\n‚ö†Ô∏è  –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¶–¢–ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {ctk_dir}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        print("\nüìä –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ö—Ä–∞–Ω–∏–ª–∏—â:")
        final_store_info = loader.get_store_info()
        for store_name, info in final_store_info.items():
            if "error" not in info:
                status_icon = "‚úÖ" if info["status"] == "ready" else "‚ö†Ô∏è"
                print(f"   {status_icon} {store_name}: {info['documents']} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            else:
                print(f"   ‚ùå {store_name}: –æ—à–∏–±–∫–∞ - {info['error']}")
        
        print("\n‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print("–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∞–≥–µ–Ω—Ç–∞: python agent.py")
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 